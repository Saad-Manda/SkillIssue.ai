import gradio as gr
import uuid
import json
from langchain_core.messages import HumanMessage, messages_to_dict, messages_from_dict
from src.agents.orchestrator import app as graph_app
from src.agents.agent_utils.redis_utils import start_new_interview
from src.agents.agent_utils.redis_session import session_store
from src.models.user_model import User
from src.models.jd_model import JobDescription


def start_interview(user_json: str, jd_json: str):
    """
    Initialize a new interview session and generate the first question.
    """
    try:
        # Validate inputs
        if not user_json or not user_json.strip():
            return "Error: User data is required", "", ""
        
        if not jd_json or not jd_json.strip():
            return "Error: Job description is required", "", ""
        
        # Parse JSON inputs
        try:
            user_data = json.loads(user_json.strip())
        except json.JSONDecodeError as e:
            return f"Error: Invalid JSON in User Data - {str(e)}", "", ""
        
        try:
            jd_data = json.loads(jd_json.strip())
        except json.JSONDecodeError as e:
            return f"Error: Invalid JSON in Job Description - {str(e)}", "", ""
        
        # Create User and JobDescription objects from parsed JSON
        try:
            user = User(**user_data)
        except Exception as e:
            return f"Error creating User object: {str(e)}", "", ""
        
        try:
            jd = JobDescription(**jd_data)
        except Exception as e:
            return f"Error creating JobDescription object: {str(e)}", "", ""
        
        # Generate unique session ID
        session_id = str(uuid.uuid4())
        
        # Initialize session in Redis
        try:
            start_new_interview(
                session_id=session_id,
                user_data=user.model_dump(),
                jd_data=jd.model_dump(),
                summary=""  # Will be generated by summarizer
            )
        except Exception as e:
            return f"Error initializing Redis session: {str(e)}", "", ""
        
        # Create state for graph invocation
        initial_state = {
            "session_id": session_id,
            "current_user": user,
            "current_jd": jd,
            "user_summary": "",
            "chat_history": [],  # Start with empty list
            "interview_phase": "introduction",
            "next_question": None,
            "final_report": None
        }
        
        # Invoke graph to generate first question
        try:
            print(f"Invoking graph with session_id: {session_id}")
            result = graph_app.invoke(initial_state)
            print(f"Graph result type: {type(result)}")
            print(f"Graph result keys: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            print(f"Graph invocation error: {error_trace}")
            return f"Error invoking graph: {str(e)}\n\nTraceback:\n{error_trace}", "", ""
        
        # Extract question from state
        # The question_generator_node appends to chat_history as: {"question": "...", "answer": ""}
        first_question = None
        
        if isinstance(result, dict):
            # Try to get from next_question first
            first_question = result.get("next_question")
            
            # If not found, extract from chat_history
            if not first_question:
                chat_history = result.get("chat_history", [])
                if chat_history and isinstance(chat_history, list) and len(chat_history) > 0:
                    # Get the last item from chat_history
                    last_item = chat_history[-1]
                    
                    # Handle different formats
                    if isinstance(last_item, dict):
                        # Format: {"question": "...", "answer": ""}
                        first_question = last_item.get("question")
                    elif hasattr(last_item, 'content'):
                        # BaseMessage object
                        first_question = last_item.content
                    elif isinstance(last_item, dict) and 'content' in last_item:
                        # Dict with content key
                        first_question = last_item.get('content')
        
        if not first_question:
            first_question = "No question generated. Please check the console for errors."
        
        # Return session_id, first question, and chat history
        chat_display = f"Interviewer: {first_question}\n\n"
        
        return session_id, chat_display, ""
        
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"Unexpected error in start_interview: {error_trace}")
        return f"Unexpected error: {str(e)}\n\nTraceback:\n{error_trace}", "", ""


def submit_answer(session_id: str, user_answer: str, chat_history: str):
    """
    Submit user's answer, update Redis, and generate next question.
    """
    if not session_id or not session_id.strip():
        return "Please start an interview first!", chat_history, ""
    
    if not user_answer or not user_answer.strip():
        return "Please enter an answer!", chat_history, ""
    
    try:
        # Get current session from Redis
        session_data = session_store.get(session_id.strip())
        
        if not session_data or not session_data.get("session_id"):
            return "Session not found! Please start a new interview.", chat_history, ""
        
        # Get current chat_history from Redis
        chat_history_dicts = session_data.get("chat_history", [])
        
        # The chat_history in Redis is stored as list of dicts
        # We need to update the last item's "answer" field
        if chat_history_dicts and isinstance(chat_history_dicts, list) and len(chat_history_dicts) > 0:
            # Update the last question's answer
            last_item = chat_history_dicts[-1]
            if isinstance(last_item, dict):
                last_item["answer"] = user_answer.strip()
            else:
                # If format is different, append new entry
                chat_history_dicts.append({
                    "question": "",
                    "answer": user_answer.strip()
                })
        else:
            # No history yet, create new entry
            chat_history_dicts = [{
                "question": "",
                "answer": user_answer.strip()
            }]
        
        # Update Redis with user's answer
        session_store.update(
            session_id.strip(),
            chat_history=chat_history_dicts
        )
        
        # Update chat display
        updated_chat = chat_history + f"You: {user_answer.strip()}\n\n"
        
        # Load state from Redis and prepare for next question generation
        from src.models.user_model import User
        from src.models.jd_model import JobDescription
        
        # Reconstruct state from Redis data
        # Convert chat_history back to list format expected by nodes
        state_chat_history = []
        for item in chat_history_dicts:
            if isinstance(item, dict):
                state_chat_history.append(item)
            else:
                state_chat_history.append(item)
        
        state = {
            "session_id": session_data["session_id"],
            "current_user": User(**session_data["current_user"]),
            "current_jd": JobDescription(**session_data["current_jd"]),
            "user_summary": session_data.get("user_summary", ""),
            "chat_history": state_chat_history,  # List of dicts with question/answer
            "interview_phase": session_data.get("interview_phase", "introduction"),
            "next_question": None,
            "final_report": None
        }
        
        # Generate next question
        try:
            result = graph_app.invoke(state)
        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            print(f"Error generating next question: {error_trace}")
            return f"{updated_chat}Error generating next question: {str(e)}", ""
        
        # Extract next question from result state
        next_question = None
        
        if isinstance(result, dict):
            # Try to get from next_question first
            next_question = result.get("next_question")
            
            # If not found, extract from chat_history
            if not next_question:
                result_chat_history = result.get("chat_history", [])
                if result_chat_history and isinstance(result_chat_history, list) and len(result_chat_history) > 0:
                    # Get the last item (should be the new question)
                    last_item = result_chat_history[-1]
                    
                    if isinstance(last_item, dict):
                        # Format: {"question": "...", "answer": ""}
                        next_question = last_item.get("question")
                    elif hasattr(last_item, 'content'):
                        # BaseMessage object
                        next_question = last_item.content
                    elif isinstance(last_item, dict) and 'content' in last_item:
                        next_question = last_item.get('content')
        
        if not next_question:
            next_question = "Interview completed or error generating question."
        
        # Update chat display with next question
        updated_chat += f"Interviewer: {next_question}\n\n"
        
        # Update Redis with the new chat_history from result
        if isinstance(result, dict):
            result_chat_history = result.get("chat_history", [])
            if result_chat_history:
                # Convert to serializable format if needed
                serializable_history = []
                for item in result_chat_history:
                    if isinstance(item, dict):
                        serializable_history.append(item)
                    else:
                        # Convert BaseMessage or other objects to dict
                        serializable_history.append({
                            "question": getattr(item, 'content', str(item)),
                            "answer": ""
                        })
                
                session_store.update(
                    session_id.strip(),
                    chat_history=serializable_history
                )
        
        return updated_chat, ""  # Clear answer input
        
    except Exception as e:
        import traceback
        error_msg = f"Error: {str(e)}\n{traceback.format_exc()}"
        print(f"Error in submit_answer: {error_msg}")
        return f"{chat_history}\n‚ùå {error_msg}", ""


# Gradio Interface
with gr.Blocks(title="Mock Interview - SkillIssue.ai") as demo:
    gr.Markdown("# üé§ Mock Interview System")
    gr.Markdown("Start an interview session and answer questions interactively.")
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### Session Setup")
            user_input = gr.Textbox(
                label="User Data (JSON)",
                placeholder='{"name": "John Doe", "skills": ["Python"]}',
                lines=3
            )
            jd_input = gr.Textbox(
                label="Job Description (JSON)",
                placeholder='{"job_title": "Senior Engineer", "required_skills": ["Python"]}',
                lines=3
            )
            start_btn = gr.Button("Start Interview", variant="primary")
        
        with gr.Column(scale=2):
            gr.Markdown("### Interview Chat")
            session_id_display = gr.Textbox(
                label="Session ID",
                interactive=False,
                visible=False
            )
            chat_display = gr.Textbox(
                label="Conversation",
                lines=15,
                interactive=False,
                placeholder="Start an interview to begin..."
            )
            answer_input = gr.Textbox(
                label="Your Answer",
                placeholder="Type your answer here...",
                lines=3
            )
            submit_btn = gr.Button("Submit Answer", variant="primary")
    
    # Event handlers
    start_btn.click(
        fn=start_interview,
        inputs=[user_input, jd_input],
        outputs=[session_id_display, chat_display, answer_input]
    )
    
    submit_btn.click(
        fn=submit_answer,
        inputs=[session_id_display, answer_input, chat_display],
        outputs=[chat_display, answer_input]
    )
    
    # Allow Enter key to submit answer
    answer_input.submit(
        fn=submit_answer,
        inputs=[session_id_display, answer_input, chat_display],
        outputs=[chat_display, answer_input]
    )


if __name__ == "__main__":
    demo.launch(share=False)